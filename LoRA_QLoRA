量化调优QLoRA


1, 浮点数

LoRA相关的先到此为止，我们开始QLoRA，在开始QLoRA之前，我们先快速了解一下浮点数在计算机中是如何表示的，
在IEEE中，定义了浮点数的规范，比如‌单精度（32位）和‌双精度（64位）等格式，在二进制中通过3部分表示
这里我们是快速了解，我们举例一个简单的例子来说明，用一个32位的浮点举例，如：-101.0000001
1，符号位：占用1位，0表示正数，1表示负数
2，阶码位：占用8位，存储实际指数
3，尾数位：占用23位，存储小数点后面的值

1位就是1个bit
bit（比特）：计算机存储的最小单位，表示二进制中的0或1
Byte（字节）：由8个bit组成，是存储和传输的基本单位，二进制中用的2的8次方表示

以上就是浮点数的内容，我们开始QLoRA




2, QLoRA的公式

QLoRA公式
	Output = W_quantized + (AB)x

下面是说明
	Output:  表示输出的向量
	W_quantized:  表示经过量化后的权重矩阵
	AB:  表示LoRA中的矩阵
	x:  表示输入的向量


QLoRA技术栈公式
 	QLoRA = 4bit量化 + LoRA + 双重量化 + 分页器优化

下面是说明
	4bit量化：节省内存，将于训练模型的权重量化为4位的精度
	LoRA：通过低秩矩阵来进行参数高效微调
	双重量化：对量化参数进行再次量化，进一步压缩存储，这里主要是对缩放因子处理，此参数用可以来控制LoRA权重
	分页器优化：管理显存，通过分页优化器状态在训练过程中减少资源占用，从而防止内存溢出

  我们来对QLoRA的代码进行一个了解，示例代码当中，首先我们通过BitsAndBytesConfig，对QLoRA进行了一个配置，配置中开启了双重量化，配置中的参数意思在注释中有解释，请认真阅读代码示例，现在我们有了这个配置以后，紧接着就是要加载BaseModel模型。
  在加载BaseModel的时候，直接应用， 这样就会将BaseModel加载的时就进行4-bit量化，极大地减少内存占用。
  然后就是设置LoRAConfig，这个我们在前面的篇幅中讲过如何设置，这里由于用的是QLoRA，可以适当的提高rank来进行训练。
  最后就是TrainingArguments里面需要注意的是，optim需要改成使用分页优化器，并且开启梯度检查点。
  这里我们在回顾一下QLoRA技术栈，来加深印象：QLoRA = 4bit量化 + LoRA + 双重量化 + 分页器优化.






3, 量化

	在文章开始，我们讲了浮点数，现在我们对浮点数已经有所了解，文章当中也讲了QLoRA，并且也有示例代码，里面也包含了4bit量化和双重量化的参数。接下来我们来了解另外一个知识，“量化”。
	比较常用的三个算法是:
	AbsMax：绝对最大值（优点：简单高效。缺点：异常值敏感并且会放大误差。）
	ZeroPoint：零点（优点： 精度高，适用于非对称分布。缺点： 额外的零点会增加计算开销。）
	Quantile:：分位数（优点： 对异常值的鲁棒性强。缺点： 需要计算分位点，实现稍复杂。）
	

	压缩原理：
	
	3.1 AbsMax
	我们用AbsMax来简单表示压缩原理，比如我们要对一个数组进行压缩。
	数组里面的值有old_array = [100, 2000, 30000]，我们按照公式来进行。
	scale = 127 / max
	这里这个max是30000，如果这个max用的是int32，那么需要占用内存4个字节。
	公式里面的127表示int8，选择127而非128是为了避免对称量化时溢出（量化范围为[-127, 127]）
	scale是缩放关键值，0.00423333，也可以叫缩放因子，这个值在后续反压缩中还会使用。
	有了scale，我们开始对这个数组进行量化，这个未量化的数组，我们比喻 old_array
	通过这个缩放值来得到进行的数组，那么就是： new_array = round(old_array / scale)
	这个时候，这个new_array里面的值都是被压缩过的，也就是被量化过的值。
	如果需要反量化的时候，就需要通过这样来获得：my_array =  new_array * scale
	当然，这进行量化和反量化的时候，会存在误差，误差越大，就会导致量模型会有问题，所以不同的算法会带来不同的量化效果。
	由于是简单表示，以上就是AbsMax的原理

	3.2 ZeroPoint
  接着我们来简单表示ZeroPoint的原理，这里我们同样用数组来进行示例。
  数组里面的值是old_array = [100, 2000, 30000]，并且确定好量化范围，由于上面的案例已经用了[-127, 127]，这个案例使用的范围是0-255，现在我们用公式来说明。

  1，量化范围
  quant_min = 0
  quant_max = 255
  
  2，量化公式
  scale = (Max - Min) / (quant_max - quant_min)
        zero_point = round(quant_min - (Min / scale))
  new_array = clamp( round( old_array / scale + zero_point ), quant_min, quant_max )
  
  公式中的round是取整，比如value = round(0.853), value变成1
        公式中的clamp表示确保所有值都在这个合法范围内
  公式中的Max表示最大值，比如old_array中的30000，Min表示最小值，比如old_array中的内容表示100，然后把最大值和最小值进行除255的操作，那么得到的scale值是：117.2549
  
  这个scale称为缩放因子，这里我们通过这个scale计算零点值，按照公式进行：
  zero_point = round(0 - (100 / 117.2549)) = round(-0.853) = -1
  
  现在我们有了scale和zero_point，我们要对old_array的值进行量化
  
  对于 old_array中的第一个值100：
  100 / 117.2549 ≈ 0.853
  0.853 + (-1) = -0.147
  round(-0.147) = 0
  clamp(0, 0, 255) = 0
  
  对于 old_array中的第二个值2000：
  2000 / 117.2549 ≈ 17.055
  17.055 + (-1) = 16.055
  round(16.055) = 16
  clamp(16, 0, 255) = 16
  
  对于 old_array中的第三个值30000：
  30000 / 117.2549 ≈ 255.853
  255.853 + (-1) = 254.853
  round(254.853) = 255
  clamp(255, 0, 255) = 255
  这样，我们得到的new_array的内容就是：new_array = [0, 16, 255]，这个压缩后的值就是zeropoint量化后的，那么要恢复的话，同样也是需要用到zero_point和缩放因子scale，这里再次强调一下，请注意，使用zeropoint量化，我们恢复后的同样会存在误差。
  


  3.3 Quantile
  现在我们讲解最后一个概念：分位数。
  分位数是数据分布中的"分割点"。我用一个例子来说明：我们一般一天喝水在3L-5L左右，一天如果低于2L的水我们表示有损健康的风险，而同样，超过5L会有水中毒的风险。从而可以出现一个分布状态0L—1L—2L—3L—4L—5L，有了数据后，我们怎么使用分位数：
  
  ‌中位数‌：50%分位数，将数据分为两半。
  ‌多分位数‌：例如0%，25%，50%，75%，100%，将数据分割成多份。
  其他分割方式等等。
  ‌分位数的计算公式‌
  对于提供的饮水例子(0L-5L的分布)，我们可以这样计算分位数：
  
  ‌确定数据位置‌：第p分位数的位置 = p × (n + 1)，其中n是数据总数。
  ‌计算分数值‌：如果位置是整数，直接取该位置的值；如果不是整数，取相邻两个值的加权平均。
  例如，对于6个数据点(0L, 1L, 2L, 3L, 4L, 5L)：
  
  中位数(50%分位数)位置 = 0.5 × (6+1) = 3.5 → 取第3个(2L)和第4个(3L)的平均值 = 2.5L
  25%分位数位置 = 0.25 × 7 = 1.75 → 取第1个(1L)和第2个(2L)的加权平均值 = 1L + 0.75×(2L-1L) = 1.75L
  75%分位数位置 = 0.75 × 7 = 5.25 → 取第5个(4L)和第6个(5L)的加权平均值 = 4L + 0.25×(5L-4L) = 4.25L
  ‌分位数的实际应用‌
  在饮水例子中：
  
  ‌25%分位数(1.75L)‌：表示有25%的人饮水量低于1.75L
  ‌中位数(2.5L)‌：表示一半人饮水量低于2.5L
  ‌75%分位数(4.25L)‌：表示75%的人饮水量低于4.25L
  这样就能清楚地看出饮水量的分布情况，判断哪些人可能饮水不足或过量。

大白话学习人工智能
---------------
黄金三要素
1，什么是transformer
2，transformer能干什么
3，transformer原理，怎么使用transformer
------


1，transformer是google在2017年提出的，人工智能神经网络框架
2，transformer可以通过注意力机制（这块要考），自注意力机制，然后并行计算注意力之间的关联，得出概率最高的内容
3，transformer原理就是input embedding，position embedding，Encode，DeCode，output

------

没明白？
下面的示例是简单演示，大概的工作原理，只做参考，如果想了解真正的处理方式，请自行查看google的论文

开始：

小明和小红今天晚上一起去看电影，她觉得电影不好看！

这个她是谁？

---------------------------------------------------------------------------------------------------------------------------------------------------------
                input embeding            postion embeding                  Encode                    Decode                  output
---------------------------------------------------------------------------------------------------------------------------------------------------------
                          
         ->[小明]      ->0.2      ->(小明和男人出现的几率比较高，映射建立1， 小明和教科书出现的几率比较高，映射建立2, ...)   ->(权重0.1)她表示小明的几率不大，不是小明 ->
         ->[小红]      ->0.811    ->(小红和女人出现的几率比较高，映射建立1， 小红和卡通片出现的几率比较高，映射建立2, ...)   ->(权重0.5)她很大的概率是小红           ->
 【她】   ->[今天]      ->0.11     ->(今天和天气出现的几率比较高，映射建立1， 今天和加班出现的几率比较高，映射建立2, ...)     ->(权重0.3)她和今天这个词有一点几率      ->  [汇总输入] ->她表示（小红）
         ->[晚上]      ->0.01     ->(晚上和吃饭出现的几率比较高，映射建立1， 晚上和电影出现的几率比较高，映射建立2, ...)     ->(权重0.2)她和晚上这个词有一点几率      ->
         ->[去看]      ->0.15     ->(建立映射关系1,2,3...)                                                         ->(权重0.0)无关联                    ->
         ->[电影]      ->0.55     ->(建立映射关系1,2,3...)                                                         ->(权重0.0)无关联                    ->
 

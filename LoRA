1，什么是LoRA， LoRA，即Low-Rank Adaptation，是一种新颖的参数高效微调方法，它通过引入低秩分解来调整预训练模型的权重
2，LoRA的流程，1准备数据，2，制定rank，3，进行训练
3，LoRA的原理：

  3.1，公式：W + a (AB)，原理是冻结参数
  3.2，定义rank，a【输入， r】 进行降维压缩，b 【r， 输出】 进行升维恢复（b的初始值为0，）
  3.3，定义a的梯度，b的梯度，
  3.4，输入的值 @ a，进行压缩，压缩后的值 @ b进行恢复
  3.5，lora后的+原始的，进行合并


